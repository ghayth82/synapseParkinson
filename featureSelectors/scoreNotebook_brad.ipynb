{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDIR = '/home/pataki/synapse/gitParkinson' # base directory of the github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pataki/synapse/gitParkinson/featureSelectors\n"
     ]
    }
   ],
   "source": [
    "cd $baseDIR/featureSelectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Balint Armin Pataki!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i ../src/sc2FitModels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phenotype, trainX, trainY, testX, testY):\n",
    "    ensemble = train_ensemble(trainX, trainY)\n",
    "    \n",
    "    results, y_score, y_true = getNonLinearInterpAupr(testX, testY,\n",
    "            np.arange(len(CATEGORY_WEIGHTS[phenotype])), ensemble)\n",
    "    if phenotype == 'tremor':\n",
    "        weighted_aupr = getWeightedMean(phenotype, results)\n",
    "    else:\n",
    "        weighted_aupr = results[0]\n",
    "\n",
    "    return weighted_aupr, y_score, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportances(clf, DF):\n",
    "    tmpDF = pd.DataFrame({'imp': clf.feature_importances_, \n",
    "                  'feature':DF.columns.tolist()}).sort_values('imp', ascending=False)\n",
    "    return(tmpDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEvaluator(classifier, features, featureDB, repeatNum = 5, baseSeed = 4242, \n",
    "                     testPatientNum = 5, importance = True):\n",
    "    prAUClist = []\n",
    "    basePRauc = []\n",
    "    for i in pb(range(repeatNum)):\n",
    "        rndState = np.random.RandomState(seed=baseSeed+137*i)\n",
    "        testPatients = list(rndState.choice(pd.unique(featureDB.patient), testPatientNum, replace=False))\n",
    "\n",
    "        trainX = featureDB[~featureDB.patient.isin(testPatients)]\n",
    "        trainY = trainX.pop('bradykinesiaScore')\n",
    "        trainX.pop('patient')\n",
    "        trainX.pop('dataFileHandleId')\n",
    "        trainX = trainX[features]\n",
    "\n",
    "        testX = featureDB[featureDB.patient.isin(testPatients)]\n",
    "        testY = testX.pop('bradykinesiaScore')\n",
    "        testX.pop('patient')\n",
    "        testX.pop('dataFileHandleId')\n",
    "        testX = testX[features]\n",
    "\n",
    "        classifier.fit(trainX, list(trainY))\n",
    "\n",
    "        prAUClist.append(nonLinearInterpAupr(y_true=list(testY), y_score=classifier.predict_proba(testX).T[1])[0])\n",
    "        basePRauc.append(sum(testY)/len(testY)) # score for random guessing\n",
    "        \n",
    "    print([ '%.3f' % elem[0] for elem in prAUClist])\n",
    "    print([ '%.3f' % elem    for elem in basePRauc])\n",
    "    \n",
    "    if(importance):\n",
    "        return(getFeatureImportances(classifier, testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../src/helperFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3016, 12)\n",
      "Test shape:  (1409, 12)\n",
      "Merged:      (4425, 12)\n",
      "Remained shape: (4280, 14)\n"
     ]
    }
   ],
   "source": [
    "mainDF = mainDFCreator('bradykinesiaScore')\n",
    "\n",
    "mainDF = mainDFtrimmer(mainDF, fileMinLen=1, plot=False)\n",
    "mainDF = mainDF[['dataFileHandleId', 'bradykinesiaScore', 'patient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDF            = pd.read_csv('../sub2.3_brad/featureDB/baseFeatures.tsv', sep='\\t')\n",
    "baseFeatures      = list(set(baseDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "empiricalDF       = pd.read_csv('../sub2.3_brad/featureDB/empiricalFeature.tsv', sep='\\t')\n",
    "empiricalFeatures = list(set(empiricalDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "fourierDF         = pd.read_csv('../sub2.3_brad/featureDB/fourierFeatures.tsv', sep='\\t')\n",
    "fourierFeatures   = list(set(fourierDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "rangeStdDF        = pd.read_csv('../sub2.3_brad/featureDB/rangeStdFeatures.tsv', sep='\\t')\n",
    "rangeStdFeatures  = list(set(rangeStdDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "tsfreshDF         = pd.read_csv('../sub2.3_brad/featureDB/tsFresh_fillNA_dropConstant.tsv', sep='\\t')\n",
    "tsfreshFeatures   = list(set(tsfreshDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "autocorrDF        = pd.read_csv('../sub2.3_brad/featureDB/autoCorrFeatures.tsv', sep='\\t')\n",
    "autocorrFeatures  = list(set(autocorrDF.columns.tolist()) - set(['dataFileHandleId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF = pd.merge(mainDF, baseDF,      on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, empiricalDF, on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, fourierDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, rangeStdDF,  on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, tsfreshDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, autocorrDF,  on = 'dataFileHandleId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2911, 3015)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF = mainDF.copy(deep=True)\n",
    "allDF[allDF.columns.tolist()[3:]] = StandardScaler().fit_transform(allDF[allDF.columns.tolist()[3:]])\n",
    "mainDF = allDF[allDF.bradykinesiaScore != 'Score']\n",
    "mainDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.850', '0.704', '0.735', '0.766', '0.790']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:37<00:00,  7.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.735', '0.419', '0.772', '0.817', '0.840']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp400 = featImp0.head(400).feature.tolist()\n",
    "featImp200 = featImp0.head(200).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.819', '0.599', '0.825', '0.854', '0.873']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp400, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:27<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.831', '0.608', '0.847', '0.870', '0.879']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp200, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp100 = featImp0.head(100).feature.tolist()\n",
    "featImp50 = featImp0.head(50).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.858', '0.677', '0.860', '0.882', '0.886']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp100, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.878', '0.697', '0.875', '0.892', '0.895']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp50, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp30 = featImp0.head(30).feature.tolist()\n",
    "featImp20 = featImp0.head(20).feature.tolist()\n",
    "featImp10 = featImp0.head(10).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.886', '0.683', '0.878', '0.894', '0.895']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp30, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.878', '0.681', '0.873', '0.889', '0.907']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp20, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.855', '0.629', '0.859', '0.889', '0.922']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp10, mainDF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best is top50-30-20-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:20<00:00, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.898', '0.739', '0.855', '0.876', '0.888']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp50, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:15<00:00, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.896', '0.726', '0.874', '0.894', '0.894']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp30, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:09<00:00, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.876', '0.718', '0.871', '0.888', '0.897']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp20, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:07<00:00, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.846', '0.645', '0.853', '0.885', '0.917']\n",
      "['0.212', '0.132', '0.316', '0.318', '0.302']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp10, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4278"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4166"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subTemplate = pd.read_csv('../bradykinesiaSubmissionTemplate.csv', sep=',')[['dataFileHandleId']]\n",
    "len(subTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.merge(subTemplate, allDF, how = 'left', on = 'dataFileHandleId')\n",
    "fullDF = fullDF.fillna(fullDF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4166"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF[['dataFileHandleId'] + featImp50].to_csv('../featureDB/final_brad_50.csv', sep=',', index=False)\n",
    "fullDF[['dataFileHandleId'] + featImp30].to_csv('../featureDB/final_brad_30.csv',   sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
