{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDIR = '/home/pataki/synapse/gitParkinson' # base directory of the github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pataki/synapse/gitParkinson/featureSelectors\n"
     ]
    }
   ],
   "source": [
    "cd $baseDIR/featureSelectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Balint Armin Pataki!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i ../src/sc2FitModels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phenotype, trainX, trainY, testX, testY):\n",
    "    ensemble = train_ensemble(trainX, trainY)\n",
    "    \n",
    "    results, y_score, y_true = getNonLinearInterpAupr(testX, testY,\n",
    "            np.arange(len(CATEGORY_WEIGHTS[phenotype])), ensemble)\n",
    "    if phenotype == 'tremor':\n",
    "        weighted_aupr = getWeightedMean(phenotype, results)\n",
    "    else:\n",
    "        weighted_aupr = results[0]\n",
    "\n",
    "    return weighted_aupr, y_score, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportances(clf, DF):\n",
    "    tmpDF = pd.DataFrame({'imp': clf.feature_importances_, \n",
    "                  'feature':DF.columns.tolist()}).sort_values('imp', ascending=False)\n",
    "    return(tmpDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEvaluator(classifier, features, featureDB, repeatNum = 5, baseSeed = 4242, \n",
    "                     testPatientNum = 5, importance = True):\n",
    "    prAUClist = []\n",
    "    basePRauc = []\n",
    "    for i in pb(range(repeatNum)):\n",
    "        rndState = np.random.RandomState(seed=baseSeed+137*i)\n",
    "        testPatients = list(rndState.choice(pd.unique(featureDB.patient), testPatientNum, replace=False))\n",
    "\n",
    "        trainX = featureDB[~featureDB.patient.isin(testPatients)]\n",
    "        trainY = trainX.pop('dyskinesiaScore')\n",
    "        trainX.pop('patient')\n",
    "        trainX.pop('dataFileHandleId')\n",
    "        trainX = trainX[features]\n",
    "\n",
    "        testX = featureDB[featureDB.patient.isin(testPatients)]\n",
    "        testY = testX.pop('dyskinesiaScore')\n",
    "        testX.pop('patient')\n",
    "        testX.pop('dataFileHandleId')\n",
    "        testX = testX[features]\n",
    "\n",
    "        classifier.fit(trainX, list(trainY))\n",
    "\n",
    "        prAUClist.append(nonLinearInterpAupr(y_true=list(testY), y_score=classifier.predict_proba(testX).T[1])[0])\n",
    "        basePRauc.append(sum(testY)/len(testY)) # score for random guessing\n",
    "        \n",
    "    print([ '%.3f' % elem[0] for elem in prAUClist])\n",
    "    print([ '%.3f' % elem    for elem in basePRauc])\n",
    "    \n",
    "    if(importance):\n",
    "        return(getFeatureImportances(classifier, testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../src/helperFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1556, 12)\n",
      "Test shape:  (660, 12)\n",
      "Merged:      (2216, 12)\n",
      "Remained shape: (2143, 14)\n"
     ]
    }
   ],
   "source": [
    "mainDF = mainDFCreator('dyskinesiaScore')\n",
    "\n",
    "mainDF = mainDFtrimmer(mainDF, fileMinLen=1, plot=False)\n",
    "mainDF = mainDF[['dataFileHandleId', 'dyskinesiaScore', 'patient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDF            = pd.read_csv('../sub2.2_dysk/featureDB/baseFeatures.tsv', sep='\\t')\n",
    "baseFeatures      = list(set(baseDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "empiricalDF       = pd.read_csv('../sub2.2_dysk/featureDB/empiricalFeature.tsv', sep='\\t')\n",
    "empiricalFeatures = list(set(empiricalDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "fourierDF         = pd.read_csv('../sub2.2_dysk/featureDB/fourierFeatures.tsv', sep='\\t')\n",
    "fourierFeatures   = list(set(fourierDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "rangeStdDF        = pd.read_csv('../sub2.2_dysk/featureDB/rangeStdFeatures.tsv', sep='\\t')\n",
    "rangeStdFeatures  = list(set(rangeStdDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "tsfreshDF         = pd.read_csv('../sub2.2_dysk/featureDB/tsFresh_fillNA_dropConstant.tsv', sep='\\t')\n",
    "tsfreshFeatures   = list(set(tsfreshDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "autocorrDF        = pd.read_csv('../sub2.2_dysk/featureDB/autoCorrFeatures.tsv', sep='\\t')\n",
    "autocorrFeatures  = list(set(autocorrDF.columns.tolist()) - set(['dataFileHandleId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF = pd.merge(mainDF, baseDF,      on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, empiricalDF, on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, fourierDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, rangeStdDF,  on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, tsfreshDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, autocorrDF,  on = 'dataFileHandleId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 3001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF = mainDF.copy(deep=True)\n",
    "allDF[allDF.columns.tolist()[3:]] = StandardScaler().fit_transform(allDF[allDF.columns.tolist()[3:]])\n",
    "mainDF = allDF[allDF.dyskinesiaScore != 'Score']\n",
    "mainDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.416', '0.263', '0.121', '0.276', '0.344']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.771', '0.109', '0.445', '0.488', '0.732']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp400 = featImp0.head(400).feature.tolist()\n",
    "featImp200 = featImp0.head(200).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.786', '0.121', '0.397', '0.514', '0.711']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp400, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.788', '0.130', '0.532', '0.537', '0.743']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp200, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp100 = featImp0.head(100).feature.tolist()\n",
    "featImp50 = featImp0.head(50).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.784', '0.145', '0.513', '0.529', '0.773']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp100, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.804', '0.191', '0.496', '0.552', '0.829']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp50, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp30 = featImp0.head(30).feature.tolist()\n",
    "featImp20 = featImp0.head(20).feature.tolist()\n",
    "featImp10 = featImp0.head(10).feature.tolist()\n",
    "featImp5 = featImp0.head(5).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.783', '0.322', '0.571', '0.581', '0.829']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp30, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.794', '0.362', '0.623', '0.554', '0.824']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp20, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.809', '0.317', '0.619', '0.581', '0.818']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp10, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.764', '0.252', '0.395', '0.513', '0.740']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp5, mainDF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thes best is the top10, top30, top20, top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:42<00:00,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.757', '0.301', '0.464', '0.524', '0.760']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp50, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:39<00:00,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.746', '0.324', '0.442', '0.535', '0.742']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp30, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:38<00:00,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.786', '0.385', '0.446', '0.556', '0.784']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp20, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.770', '0.378', '0.532', '0.552', '0.759']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp10, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subTemplate = pd.read_csv('../dyskinesiaSubmissionTemplate.csv', sep=',')[['dataFileHandleId']]\n",
    "len(subTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2142"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.merge(subTemplate, allDF, how = 'left', on = 'dataFileHandleId')\n",
    "fullDF = fullDF.fillna(fullDF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF[['dataFileHandleId'] + featImp10].to_csv('../featureDB/final_dysk_10.csv', sep=',', index=False)\n",
    "fullDF[['dataFileHandleId'] + featImp30].to_csv('../featureDB/final_dsyk_30.csv',   sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
