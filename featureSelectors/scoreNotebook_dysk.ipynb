{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseDIR = '/home/pataki/synapse/gitParkinson/' # base directory of the github repo\n",
    "#uncomment the line above (+ update) if you are running this notebook in an empty namespace\n",
    "try: baseDIR\n",
    "except NameError:\n",
    "    print('Error: baseDIR not found!')\n",
    "    \n",
    "try: coreNum\n",
    "except NameError:\n",
    "    coreNum = 4 # default CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pataki/synapse/gitParkinson/featureSelectors\n"
     ]
    }
   ],
   "source": [
    "cd $baseDIR/featureSelectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../src/sc2FitModels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phenotype, trainX, trainY, testX, testY):\n",
    "    ensemble = train_ensemble(trainX, trainY)\n",
    "    \n",
    "    results, y_score, y_true = getNonLinearInterpAupr(testX, testY,\n",
    "            np.arange(len(CATEGORY_WEIGHTS[phenotype])), ensemble)\n",
    "    if phenotype == 'tremor':\n",
    "        weighted_aupr = getWeightedMean(phenotype, results)\n",
    "    else:\n",
    "        weighted_aupr = results[0]\n",
    "\n",
    "    return weighted_aupr, y_score, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportances(clf, DF):\n",
    "    tmpDF = pd.DataFrame({'imp': clf.feature_importances_, \n",
    "                  'feature':DF.columns.tolist()}).sort_values('imp', ascending=False)\n",
    "    return(tmpDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEvaluator(classifier, features, featureDB, repeatNum = 5, baseSeed = 4242, \n",
    "                     testPatientNum = 5, importance = True):\n",
    "    prAUClist = []\n",
    "    basePRauc = []\n",
    "    for i in pb(range(repeatNum)):\n",
    "        rndState = np.random.RandomState(seed=baseSeed+137*i)\n",
    "        testPatients = list(rndState.choice(pd.unique(featureDB.patient), testPatientNum, replace=False))\n",
    "\n",
    "        trainX = featureDB[~featureDB.patient.isin(testPatients)]\n",
    "        trainY = trainX.pop('dyskinesiaScore')\n",
    "        trainX.pop('patient')\n",
    "        trainX.pop('dataFileHandleId')\n",
    "        trainX = trainX[features]\n",
    "\n",
    "        testX = featureDB[featureDB.patient.isin(testPatients)]\n",
    "        testY = testX.pop('dyskinesiaScore')\n",
    "        testX.pop('patient')\n",
    "        testX.pop('dataFileHandleId')\n",
    "        testX = testX[features]\n",
    "\n",
    "        classifier.fit(trainX, list(trainY))\n",
    "\n",
    "        prAUClist.append(nonLinearInterpAupr(y_true=list(testY), y_score=classifier.predict_proba(testX).T[1])[0])\n",
    "        basePRauc.append(sum(testY)/len(testY)) # score for random guessing\n",
    "        \n",
    "    print([ '%.3f' % elem[0] for elem in prAUClist])\n",
    "    print([ '%.3f' % elem    for elem in basePRauc])\n",
    "    \n",
    "    if(importance):\n",
    "        return(getFeatureImportances(classifier, testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../src/helperFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1556, 12)\n",
      "Test shape:  (660, 12)\n",
      "Merged:      (2216, 12)\n",
      "Remained shape: (2143, 14)\n"
     ]
    }
   ],
   "source": [
    "mainDF = mainDFCreator('dyskinesiaScore')\n",
    "\n",
    "mainDF = mainDFtrimmer(mainDF, fileMinLen=1, plot=False)\n",
    "mainDF = mainDF[['dataFileHandleId', 'dyskinesiaScore', 'patient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDF            = pd.read_csv('../sub2.2_dysk/featureDB/baseFeatures.tsv', sep='\\t')\n",
    "baseFeatures      = list(set(baseDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "empiricalDF       = pd.read_csv('../sub2.2_dysk/featureDB/empiricalFeature.tsv', sep='\\t')\n",
    "empiricalFeatures = list(set(empiricalDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "fourierDF         = pd.read_csv('../sub2.2_dysk/featureDB/fourierFeatures.tsv', sep='\\t')\n",
    "fourierFeatures   = list(set(fourierDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "rangeStdDF        = pd.read_csv('../sub2.2_dysk/featureDB/rangeStdFeatures.tsv', sep='\\t')\n",
    "rangeStdFeatures  = list(set(rangeStdDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "tsfreshDF         = pd.read_csv('../sub2.2_dysk/featureDB/tsFresh_fillNA_dropConstant.tsv', sep='\\t')\n",
    "tsfreshFeatures   = list(set(tsfreshDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "autocorrDF        = pd.read_csv('../sub2.2_dysk/featureDB/autoCorrFeatures.tsv', sep='\\t')\n",
    "autocorrFeatures  = list(set(autocorrDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "baseFeatures.sort()     # to avoid randomness\n",
    "empiricalFeatures.sort()\n",
    "fourierFeatures.sort()\n",
    "rangeStdFeatures.sort()\n",
    "tsfreshFeatures.sort()\n",
    "autocorrFeatures.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF = pd.merge(mainDF, baseDF,      on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, empiricalDF, on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, fourierDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, rangeStdDF,  on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, tsfreshDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, autocorrDF,  on = 'dataFileHandleId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 3025)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF = mainDF.copy(deep=True)\n",
    "allDF[allDF.columns.tolist()[3:]] = StandardScaler().fit_transform(allDF[allDF.columns.tolist()[3:]])\n",
    "mainDF = allDF[allDF.dyskinesiaScore != 'Score']\n",
    "mainDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.416', '0.262']\n",
      "['0.276', '0.069']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:06<00:00, 13.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.761', '0.115', '0.473', '0.493', '0.699']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp400 = featImp0.head(400).feature.tolist()\n",
    "featImp200 = featImp0.head(200).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:37<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.781', '0.125', '0.427', '0.522', '0.725']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp400, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:34<00:00,  6.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.785', '0.128', '0.517', '0.544', '0.752']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp200, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp100 = featImp0.head(100).feature.tolist()\n",
    "featImp50 = featImp0.head(50).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.781', '0.152', '0.431', '0.546', '0.772']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp100, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:33<00:00,  6.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.790', '0.184', '0.477', '0.530', '0.797']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp50, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featImp30 = featImp0.head(30).feature.tolist()\n",
    "featImp20 = featImp0.head(20).feature.tolist()\n",
    "featImp10 = featImp0.head(10).feature.tolist()\n",
    "featImp5 = featImp0.head(5).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.792', '0.320', '0.520', '0.530', '0.793']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp30, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.815', '0.307', '0.614', '0.602', '0.826']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp20, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.806', '0.337', '0.646', '0.599', '0.850']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp10, mainDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.804', '0.267', '0.616', '0.565', '0.778']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=coreNum, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, featImp5, mainDF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thes best is the top10, top30, top20, top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:45<00:00, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.749', '0.208', '0.417', '0.519', '0.708']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp50, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:20<00:00, 16.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.764', '0.239', '0.404', '0.487', '0.700']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp30, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:01<00:00, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.777', '0.332', '0.439', '0.560', '0.766']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp20, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:42<00:00,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.817', '0.344', '0.601', '0.563', '0.806']\n",
      "['0.276', '0.069', '0.056', '0.170', '0.226']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "lr = OneVsRestClassifier(LogisticRegressionCV())\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm)], voting='soft')\n",
    "\n",
    "featureEvaluator(ensemble, featImp10, mainDF, importance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subTemplate = pd.read_csv('../dyskinesiaSubmissionTemplate.csv', sep=',')[['dataFileHandleId']]\n",
    "len(subTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2142"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.merge(subTemplate, allDF, how = 'left', on = 'dataFileHandleId')\n",
    "fullDF = fullDF.fillna(fullDF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF[['dataFileHandleId'] + featImp10].to_csv('../featureDB/final_dysk_10.csv', sep=',', index=False)\n",
    "fullDF[['dataFileHandleId'] + featImp30].to_csv('../featureDB/final_dysk_30.csv',   sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
