{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDIR = '/home/pataki/synapse/gitParkinson' # base directory of the github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pataki/synapse/gitParkinson/featureSelectors\n"
     ]
    }
   ],
   "source": [
    "cd $baseDIR/featureSelectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Balint Armin Pataki!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i ../src/sc2FitModels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phenotype, trainX, trainY, testX, testY):\n",
    "    ensemble = train_ensemble(trainX, trainY)\n",
    "    \n",
    "    results, y_score, y_true = getNonLinearInterpAupr(testX, testY,\n",
    "            np.arange(len(CATEGORY_WEIGHTS[phenotype])), ensemble)\n",
    "    if phenotype == 'tremor':\n",
    "        weighted_aupr = getWeightedMean(phenotype, results)\n",
    "    else:\n",
    "        weighted_aupr = results[0]\n",
    "\n",
    "    return weighted_aupr, y_score, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportances(clf, DF):\n",
    "    tmpDF = pd.DataFrame({'imp': clf.feature_importances_, \n",
    "                  'feature':DF.columns.tolist()}).sort_values('imp', ascending=False)\n",
    "    return(tmpDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEvaluator(classifier, features, featureDB, repeatNum = 5, baseSeed = 4242, \n",
    "                     testPatientNum = 5, importance = True):\n",
    "    prAUClist = []\n",
    "    basePRauc = []\n",
    "    for i in pb(range(repeatNum)):\n",
    "        rndState = np.random.RandomState(seed=baseSeed+137*i)\n",
    "        testPatients = list(rndState.choice(pd.unique(featureDB.patient), testPatientNum, replace=False))\n",
    "\n",
    "        trainX = featureDB[~featureDB.patient.isin(testPatients)]\n",
    "        trainY = trainX.pop('tremorScore')\n",
    "        trainX.pop('patient')\n",
    "        trainX.pop('dataFileHandleId')\n",
    "        trainX = trainX[features]\n",
    "\n",
    "        testX = featureDB[featureDB.patient.isin(testPatients)]\n",
    "        testY = testX.pop('tremorScore')\n",
    "        testX.pop('patient')\n",
    "        testX.pop('dataFileHandleId')\n",
    "        testX = testX[features]\n",
    "\n",
    "        classifier.fit(trainX, list(trainY))\n",
    "\n",
    "        prAUClist.append(nonLinearInterpAupr(y_true=list(testY), y_score=classifier.predict_proba(testX).T[1])[0])\n",
    "        basePRauc.append(sum(testY)/len(testY)) # score for random guessing\n",
    "        \n",
    "    print([ '%.3f' % elem[0] for elem in prAUClist])\n",
    "    print([ '%.3f' % elem    for elem in basePRauc])\n",
    "    \n",
    "    if(importance):\n",
    "        return(getFeatureImportances(classifier, testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../src/helperFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3667, 12)\n",
      "Test shape:  (1500, 12)\n",
      "Merged:      (5167, 12)\n",
      "Remained shape: (5005, 14)\n"
     ]
    }
   ],
   "source": [
    "mainDF = mainDFCreator('tremorScore')\n",
    "\n",
    "mainDF = mainDFtrimmer(mainDF, fileMinLen=1, plot=False)\n",
    "mainDF = mainDF[['dataFileHandleId', 'tremorScore', 'patient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDF            = pd.read_csv('../sub2.1_tremor/featureDB/baseFeatures.tsv', sep='\\t')\n",
    "baseFeatures      = list(set(baseDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "empiricalDF       = pd.read_csv('../sub2.1_tremor/featureDB/empiricalFeature.tsv', sep='\\t')\n",
    "empiricalFeatures = list(set(empiricalDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "fourierDF         = pd.read_csv('../sub2.1_tremor/featureDB/fourierFeatures.tsv', sep='\\t')\n",
    "fourierFeatures   = list(set(fourierDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "rangeStdDF        = pd.read_csv('../sub2.1_tremor/featureDB/rangeStdFeatures.tsv', sep='\\t')\n",
    "rangeStdFeatures  = list(set(rangeStdDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "tsfreshDF         = pd.read_csv('../sub2.1_tremor/featureDB/tsFresh_fillNA_dropConstant.tsv', sep='\\t')\n",
    "tsfreshFeatures   = list(set(tsfreshDF.columns.tolist()) - set(['dataFileHandleId']))\n",
    "\n",
    "autocorrDF        = pd.read_csv('../sub2.1_tremor/featureDB/autoCorrFeatures.tsv', sep='\\t')\n",
    "autocorrFeatures  = list(set(autocorrDF.columns.tolist()) - set(['dataFileHandleId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF = pd.merge(mainDF, baseDF,      on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, empiricalDF, on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, fourierDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, rangeStdDF,  on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, tsfreshDF,   on = 'dataFileHandleId', how='inner')\n",
    "mainDF = pd.merge(mainDF, autocorrDF,  on = 'dataFileHandleId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3545, 3015)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF = mainDF.copy(deep=True)\n",
    "allDF[allDF.columns.tolist()[3:]] = StandardScaler().fit_transform(allDF[allDF.columns.tolist()[3:]])\n",
    "mainDF = allDF[allDF.tremorScore != 'Score']\n",
    "mainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score01234df = mainDF.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score0df = score01234df.copy(deep=True)\n",
    "score0df['tremorScore'] = [int(i==0) for i in score0df.tremorScore]\n",
    "\n",
    "score1df = score01234df.copy(deep=True)\n",
    "score1df['tremorScore'] = [int(i==1) for i in score1df.tremorScore]\n",
    "\n",
    "score2df = score01234df.copy(deep=True)\n",
    "score2df['tremorScore'] = [int(i==2) for i in score2df.tremorScore]\n",
    "\n",
    "score3df = score01234df.copy(deep=True)\n",
    "score3df['tremorScore'] = [int(i==3) for i in score3df.tremorScore]\n",
    "\n",
    "score4df = score01234df.copy(deep=True)\n",
    "score4df['tremorScore'] = [int(i==4) for i in score4df.tremorScore]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.872', '0.963', '0.845', '0.844', '0.793']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.468', '0.279', '0.547', '0.551', '0.608']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.139', '0.775', '0.448', '0.306', '0.246']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures, score0df) # score 0 vs other\n",
    "featImp1 = featureEvaluator(clf, baseFeatures, score1df) # score 1 vs other\n",
    "featImp2 = featureEvaluator(clf, baseFeatures, score2df) # score 2 vs other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:38<00:00,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.884', '0.971', '0.904', '0.872', '0.865']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:35<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.459', '0.360', '0.560', '0.575', '0.563']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:34<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.080', '0.530', '0.545', '0.515', '0.454']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, score0df) # score 0 vs other\n",
    "featImp1 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, score1df) # score 1 vs other\n",
    "featImp2 = featureEvaluator(clf, baseFeatures + empiricalFeatures + fourierFeatures + \n",
    "                                rangeStdFeatures + tsfreshFeatures + autocorrFeatures, score2df) # score 2 vs other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "impFeat400_0 = set(featImp0.head(400).feature.tolist())\n",
    "impFeat400_1 = set(featImp1.head(200).feature.tolist())\n",
    "impFeat400_2 = set(featImp2.head(200).feature.tolist())\n",
    "impFeat400   = list(impFeat400_0.union(impFeat400_1).union(impFeat400_2))\n",
    "\n",
    "impFeat200_0 = set(featImp0.head(200).feature.tolist())\n",
    "impFeat200_1 = set(featImp1.head(100).feature.tolist())\n",
    "impFeat200_2 = set(featImp2.head(100).feature.tolist())\n",
    "impFeat200   = list(impFeat200_0.union(impFeat200_1).union(impFeat200_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:34<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.900', '0.980', '0.910', '0.886', '0.867']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.526', '0.386', '0.556', '0.596', '0.599']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.080', '0.633', '0.521', '0.514', '0.456']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, impFeat400, score0df)\n",
    "featImp1 = featureEvaluator(clf, impFeat400, score1df)\n",
    "featImp2 = featureEvaluator(clf, impFeat400, score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:34<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.912', '0.980', '0.905', '0.893', '0.872']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.555', '0.396', '0.572', '0.597', '0.611']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.085', '0.670', '0.514', '0.494', '0.428']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, impFeat200, score0df)\n",
    "featImp1 = featureEvaluator(clf, impFeat200, score1df)\n",
    "featImp2 = featureEvaluator(clf, impFeat200, score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "impFeat100_0 = set(featImp0.head(100).feature.tolist())\n",
    "impFeat100_1 = set(featImp1.head(50).feature.tolist())\n",
    "impFeat100_2 = set(featImp2.head(50).feature.tolist())\n",
    "impFeat100   = list(impFeat100_0.union(impFeat100_1).union(impFeat100_2))\n",
    "\n",
    "impFeat50_0 = set(featImp0.head(50).feature.tolist())\n",
    "impFeat50_1 = set(featImp1.head(25).feature.tolist())\n",
    "impFeat50_2 = set(featImp2.head(25).feature.tolist())\n",
    "impFeat50   = list(impFeat50_0.union(impFeat50_1).union(impFeat50_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:33<00:00,  6.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.914', '0.979', '0.903', '0.899', '0.871']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.567', '0.400', '0.575', '0.595', '0.630']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.094', '0.720', '0.499', '0.484', '0.423']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, impFeat100, score0df)\n",
    "featImp1 = featureEvaluator(clf, impFeat100, score1df)\n",
    "featImp2 = featureEvaluator(clf, impFeat100, score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.914', '0.981', '0.917', '0.899', '0.878']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.584', '0.423', '0.599', '0.604', '0.627']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.110', '0.775', '0.507', '0.484', '0.437']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, impFeat50, score0df)\n",
    "featImp1 = featureEvaluator(clf, impFeat50, score1df)\n",
    "featImp2 = featureEvaluator(clf, impFeat50, score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "impFeat30_0   = set(featImp0.head(30).feature.tolist())\n",
    "impFeat30_1   = set(featImp1.head(15).feature.tolist())\n",
    "impFeat30_2   = set(featImp2.head(15).feature.tolist())\n",
    "impFeat30 = list(impFeat30_0.union(impFeat30_1).union(impFeat30_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.914', '0.979', '0.916', '0.898', '0.881']\n",
      "['0.668', '0.820', '0.584', '0.557', '0.521']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.587', '0.458', '0.605', '0.605', '0.629']\n",
      "['0.280', '0.097', '0.306', '0.326', '0.377']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.102', '0.801', '0.493', '0.479', '0.408']\n",
      "['0.052', '0.083', '0.110', '0.117', '0.102']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=42)\n",
    "\n",
    "featImp0 = featureEvaluator(clf, impFeat30, score0df)\n",
    "featImp1 = featureEvaluator(clf, impFeat30, score1df)\n",
    "featImp2 = featureEvaluator(clf, impFeat30, score2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subTemplate = pd.read_csv('../tremorSubmissionTemplate.csv', sep=',')[['dataFileHandleId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.merge(subTemplate, allDF, how = 'outer', on = 'dataFileHandleId')\n",
    "fullDF = fullDF.fillna(fullDF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF[['dataFileHandleId'] + impFeat30].to_csv('../featureDB/final_tremor_50.csv', sep=',', index=False)\n",
    "fullDF[['dataFileHandleId'] + impFeat50].to_csv('../featureDB/final_tremor_30.csv',   sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
